{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import InterpolationMode\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "class DataAugmentation:\n",
    "    def __init__(self,global_crops_scale=(0.4,1),local_crops_scale=(0.05,4),n_local_crops=2,output_size=112):\n",
    "\n",
    "        self.n_local_crops=n_local_crops\n",
    "        RandomGaussianBlur=lambda p: transforms.RandomApply([transforms.GaussianBlur(kernel_size=1,sigma=(0.1,2))],p=p)\n",
    "        flip_and_rotation=transforms.Compose([transforms.RandomHorizontalFlip(),transforms.RandomRotation(degrees=(10)),])\n",
    "        normalize=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,),(0.3081,)),])\n",
    "\n",
    "\n",
    "        self.global_1=transforms.Compose([\n",
    "            transforms.RandomResizedCrop(output_size,scale=global_crops_scale,interpolation=InterpolationMode.BICUBIC),\n",
    "            flip_and_rotation,\n",
    "            RandomGaussianBlur(1.0),\n",
    "            normalize\n",
    "        ])\n",
    "        self.global_2=transforms.Compose([\n",
    "            transforms.RandomResizedCrop(output_size,scale=global_crops_scale,interpolation=InterpolationMode.BICUBIC),\n",
    "            flip_and_rotation,\n",
    "            RandomGaussianBlur(0.1),\n",
    "            transforms.RandomSolarize(170,p=0.2),\n",
    "            normalize\n",
    "        ])\n",
    "        self.local=transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224,scale=local_crops_scale,interpolation=InterpolationMode.BICUBIC),\n",
    "            flip_and_rotation,\n",
    "            RandomGaussianBlur(0.5),\n",
    "            normalize\n",
    "        ])\n",
    "\n",
    "    \n",
    "    def __call__(self,image):\n",
    "        '''\n",
    "        all_crops:list of torch.Tensor\n",
    "        represent different version of input img\n",
    "        '''\n",
    "        all_crops=[]\n",
    "        all_crops.append(self.global_1(image))\n",
    "        all_crops.append(self.global_2(image))\n",
    "        all_crops.extend([self.local(image) for _ in range(self.n_local_crops)])\n",
    "        return all_crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=DataAugmentation(n_local_crops=2)\n",
    "DOWNLOAD_PATH = './data'\n",
    "dataset = torchvision.datasets.MNIST(DOWNLOAD_PATH, train=True, download=False,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(t):\n",
    "    arr=torch.clip((t*0.224)+0.45,0,1).permute(1,2,0).numpy()\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36da121ff6434818aea4e82a83bf2356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, continuous_update=False, description='i', max=59999), IntSlider(valueâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#GUI\n",
    "'''\n",
    "i: range(0,len(dataset)-1), choose a sample from dataset\n",
    "seed: choose a seed from 0 to 50\n",
    "'''\n",
    "@ipywidgets.interact\n",
    "def _(i=ipywidgets.IntSlider(min=0,max=len(dataset)-1,continuous_update=False),\n",
    "    seed=ipywidgets.IntSlider(min=0,max=50,continuous_update=False),):\n",
    "    torch.manual_seed(seed)\n",
    "    all_crops,labels=dataset[i]\n",
    "    print(\"number of crops:\",len(all_crops))\n",
    "\n",
    "    titles=['global_0','global_1','local_0','local_1']\n",
    "    orig_img=dataset.data[i]\n",
    "    fig,axs=plt.subplots(figsize=(10,10))\n",
    "    axs.imshow(orig_img)\n",
    "    axs.set_title('original_image')\n",
    "    axs.axis('off')\n",
    "\n",
    "    \n",
    "    fig,axs=plt.subplots(2,2,figsize=(10,10))\n",
    "    for i,t in enumerate(titles):\n",
    "        ax=axs[i//2,i%2]\n",
    "        ax.imshow(to_numpy(all_crops[i]))\n",
    "        ax.set_title(t)\n",
    "        ax.axis('off')\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f727375eba1284a63b4d9e638236d85d45c674565c6cacd6cfe2f9879757f3bd"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
